{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3052503052503053,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006105006105006105,
      "grad_norm": 4.648993492126465,
      "learning_rate": 4.990842490842491e-05,
      "loss": 8.6892,
      "step": 10
    },
    {
      "epoch": 0.01221001221001221,
      "grad_norm": 5.268571376800537,
      "learning_rate": 4.980667480667481e-05,
      "loss": 8.1388,
      "step": 20
    },
    {
      "epoch": 0.018315018315018316,
      "grad_norm": 6.700886249542236,
      "learning_rate": 4.971509971509972e-05,
      "loss": 7.6574,
      "step": 30
    },
    {
      "epoch": 0.02442002442002442,
      "grad_norm": 7.027956008911133,
      "learning_rate": 4.961334961334961e-05,
      "loss": 7.227,
      "step": 40
    },
    {
      "epoch": 0.030525030525030524,
      "grad_norm": 8.223382949829102,
      "learning_rate": 4.951159951159952e-05,
      "loss": 6.6618,
      "step": 50
    },
    {
      "epoch": 0.03663003663003663,
      "grad_norm": 10.327665328979492,
      "learning_rate": 4.940984940984941e-05,
      "loss": 5.6438,
      "step": 60
    },
    {
      "epoch": 0.042735042735042736,
      "grad_norm": 10.628287315368652,
      "learning_rate": 4.930809930809931e-05,
      "loss": 4.5929,
      "step": 70
    },
    {
      "epoch": 0.04884004884004884,
      "grad_norm": 11.929064750671387,
      "learning_rate": 4.9206349206349204e-05,
      "loss": 4.0153,
      "step": 80
    },
    {
      "epoch": 0.054945054945054944,
      "grad_norm": 9.384648323059082,
      "learning_rate": 4.910459910459911e-05,
      "loss": 2.9943,
      "step": 90
    },
    {
      "epoch": 0.06105006105006105,
      "grad_norm": 3.7271976470947266,
      "learning_rate": 4.9002849002849004e-05,
      "loss": 2.0259,
      "step": 100
    },
    {
      "epoch": 0.06715506715506715,
      "grad_norm": 6.245735168457031,
      "learning_rate": 4.8901098901098904e-05,
      "loss": 0.9949,
      "step": 110
    },
    {
      "epoch": 0.07326007326007326,
      "grad_norm": 0.45202869176864624,
      "learning_rate": 4.8799348799348804e-05,
      "loss": 0.6619,
      "step": 120
    },
    {
      "epoch": 0.07936507936507936,
      "grad_norm": 5.019373416900635,
      "learning_rate": 4.8697598697598704e-05,
      "loss": 1.3847,
      "step": 130
    },
    {
      "epoch": 0.08547008547008547,
      "grad_norm": 5.853128910064697,
      "learning_rate": 4.85958485958486e-05,
      "loss": 0.8637,
      "step": 140
    },
    {
      "epoch": 0.09157509157509157,
      "grad_norm": 0.2735006809234619,
      "learning_rate": 4.84940984940985e-05,
      "loss": 0.824,
      "step": 150
    },
    {
      "epoch": 0.09768009768009768,
      "grad_norm": 0.1916627585887909,
      "learning_rate": 4.83923483923484e-05,
      "loss": 1.3421,
      "step": 160
    },
    {
      "epoch": 0.10378510378510379,
      "grad_norm": 3.574775218963623,
      "learning_rate": 4.829059829059829e-05,
      "loss": 0.7217,
      "step": 170
    },
    {
      "epoch": 0.10989010989010989,
      "grad_norm": 5.297305583953857,
      "learning_rate": 4.818884818884819e-05,
      "loss": 0.75,
      "step": 180
    },
    {
      "epoch": 0.115995115995116,
      "grad_norm": 2.736884593963623,
      "learning_rate": 4.8087098087098084e-05,
      "loss": 0.851,
      "step": 190
    },
    {
      "epoch": 0.1221001221001221,
      "grad_norm": 2.3032455444335938,
      "learning_rate": 4.798534798534799e-05,
      "loss": 0.6691,
      "step": 200
    },
    {
      "epoch": 0.1282051282051282,
      "grad_norm": 0.1896502822637558,
      "learning_rate": 4.7883597883597884e-05,
      "loss": 0.4437,
      "step": 210
    },
    {
      "epoch": 0.1343101343101343,
      "grad_norm": 3.852277994155884,
      "learning_rate": 4.7781847781847784e-05,
      "loss": 0.7725,
      "step": 220
    },
    {
      "epoch": 0.14041514041514042,
      "grad_norm": 0.13078363239765167,
      "learning_rate": 4.7680097680097684e-05,
      "loss": 0.7425,
      "step": 230
    },
    {
      "epoch": 0.14652014652014653,
      "grad_norm": 0.14361204206943512,
      "learning_rate": 4.7578347578347584e-05,
      "loss": 0.4847,
      "step": 240
    },
    {
      "epoch": 0.15262515262515264,
      "grad_norm": 2.461129665374756,
      "learning_rate": 4.747659747659748e-05,
      "loss": 0.638,
      "step": 250
    },
    {
      "epoch": 0.15873015873015872,
      "grad_norm": 2.6312761306762695,
      "learning_rate": 4.737484737484738e-05,
      "loss": 0.6936,
      "step": 260
    },
    {
      "epoch": 0.16483516483516483,
      "grad_norm": 0.3096200227737427,
      "learning_rate": 4.727309727309728e-05,
      "loss": 0.5777,
      "step": 270
    },
    {
      "epoch": 0.17094017094017094,
      "grad_norm": 0.16686901450157166,
      "learning_rate": 4.717134717134717e-05,
      "loss": 0.5071,
      "step": 280
    },
    {
      "epoch": 0.17704517704517705,
      "grad_norm": 0.8105762600898743,
      "learning_rate": 4.706959706959707e-05,
      "loss": 0.5861,
      "step": 290
    },
    {
      "epoch": 0.18315018315018314,
      "grad_norm": 0.1554695963859558,
      "learning_rate": 4.696784696784697e-05,
      "loss": 0.4084,
      "step": 300
    },
    {
      "epoch": 0.18925518925518925,
      "grad_norm": 0.1684752106666565,
      "learning_rate": 4.686609686609687e-05,
      "loss": 0.4462,
      "step": 310
    },
    {
      "epoch": 0.19536019536019536,
      "grad_norm": 0.24538616836071014,
      "learning_rate": 4.6764346764346765e-05,
      "loss": 0.5463,
      "step": 320
    },
    {
      "epoch": 0.20146520146520147,
      "grad_norm": 1.2896019220352173,
      "learning_rate": 4.6662596662596665e-05,
      "loss": 0.4365,
      "step": 330
    },
    {
      "epoch": 0.20757020757020758,
      "grad_norm": 1.3694944381713867,
      "learning_rate": 4.656084656084656e-05,
      "loss": 0.397,
      "step": 340
    },
    {
      "epoch": 0.21367521367521367,
      "grad_norm": 0.14228029549121857,
      "learning_rate": 4.6459096459096465e-05,
      "loss": 0.4523,
      "step": 350
    },
    {
      "epoch": 0.21978021978021978,
      "grad_norm": 0.15452195703983307,
      "learning_rate": 4.635734635734636e-05,
      "loss": 0.402,
      "step": 360
    },
    {
      "epoch": 0.2258852258852259,
      "grad_norm": 0.20249788463115692,
      "learning_rate": 4.625559625559626e-05,
      "loss": 0.5114,
      "step": 370
    },
    {
      "epoch": 0.231990231990232,
      "grad_norm": 1.7319434881210327,
      "learning_rate": 4.615384615384616e-05,
      "loss": 0.4393,
      "step": 380
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 0.614611804485321,
      "learning_rate": 4.605209605209606e-05,
      "loss": 0.3007,
      "step": 390
    },
    {
      "epoch": 0.2442002442002442,
      "grad_norm": 0.8729228377342224,
      "learning_rate": 4.595034595034595e-05,
      "loss": 0.3824,
      "step": 400
    },
    {
      "epoch": 0.2503052503052503,
      "grad_norm": 0.21125078201293945,
      "learning_rate": 4.584859584859585e-05,
      "loss": 0.3705,
      "step": 410
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 0.8721244931221008,
      "learning_rate": 4.574684574684575e-05,
      "loss": 0.5494,
      "step": 420
    },
    {
      "epoch": 0.2625152625152625,
      "grad_norm": 0.19526134431362152,
      "learning_rate": 4.5645095645095645e-05,
      "loss": 0.5444,
      "step": 430
    },
    {
      "epoch": 0.2686202686202686,
      "grad_norm": 0.18492525815963745,
      "learning_rate": 4.5543345543345545e-05,
      "loss": 0.3732,
      "step": 440
    },
    {
      "epoch": 0.27472527472527475,
      "grad_norm": 0.15914267301559448,
      "learning_rate": 4.544159544159544e-05,
      "loss": 0.3499,
      "step": 450
    },
    {
      "epoch": 0.28083028083028083,
      "grad_norm": 0.547290563583374,
      "learning_rate": 4.5339845339845345e-05,
      "loss": 0.4379,
      "step": 460
    },
    {
      "epoch": 0.2869352869352869,
      "grad_norm": 0.18554529547691345,
      "learning_rate": 4.523809523809524e-05,
      "loss": 0.3126,
      "step": 470
    },
    {
      "epoch": 0.29304029304029305,
      "grad_norm": 0.11051855981349945,
      "learning_rate": 4.513634513634514e-05,
      "loss": 0.41,
      "step": 480
    },
    {
      "epoch": 0.29914529914529914,
      "grad_norm": 0.3540903627872467,
      "learning_rate": 4.503459503459503e-05,
      "loss": 0.3932,
      "step": 490
    },
    {
      "epoch": 0.3052503052503053,
      "grad_norm": 0.15870337188243866,
      "learning_rate": 4.493284493284494e-05,
      "loss": 0.4526,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 4914,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 524396003328000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
